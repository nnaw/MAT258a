{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Assignment 4\n",
    "\n",
    "##Nana Wang (ID: 999480980)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computing the reciprocal of a positive number $d$, we can consider the equation\n",
    "$$f(x)=\\frac{1}{x}-d=0.$$\n",
    "By calculation,\n",
    "$$f'(x)=-\\frac{1}{x^2}.$$\n",
    "Then the Newton's method for solving the equation is given as below:\n",
    "$$x_{k+1}=x_{k}-\\frac{f(x_k)}{f'(x_k)}=x_k+x_k^2\\left(\\frac{1}{x_k}-d\\right)=2x_k-dx_k^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My algorithm is as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reciprocal_newton (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reciprocal_newton(d, x0; maxIts=100, optTol=1e-8)\n",
    "    x=Float64[]; its=0\n",
    "    for i=1:maxIts\n",
    "        x=2x0-d*x0^2\n",
    "        its=its+1\n",
    "        println(\"Its=\",its,\": xk=\",x)\n",
    "        if norm(x-x0)<optTol || norm(x)==Inf\n",
    "            break;\n",
    "        end\n",
    "        x0=x\n",
    "    end\n",
    "    return x, its\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results with starting point $x_0=0.3$ and $x_0=1.0$ are listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reciprocal of e = 2.7182818284590... is: 0.36787944117144233.\n",
      "Its=1: xk=0.35535463543868595\n",
      "Its=2: xk=0.3674530222388057\n",
      "Its=3: xk=0.3678789468978142\n",
      "Its=4: xk=0.3678794411707782\n",
      "Its=5: xk=0.36787944117144233\n",
      "With starting points x0=0.3: the reciprocal of e = 2.7182818284590... is 0.36787944117144233; and iterations=5.\n",
      "Its=1: xk=-0.7182818284590451\n",
      "Its=2: xk=-2.8390034982193373\n",
      "Its=3: xk=-27.587197782518704\n",
      "Its=4: xk=-2123.9322447897025\n",
      "Its=5: xk=-1.2266656892003374e7\n",
      "Its=6: xk=-4.0902225971717706e14\n",
      "Its=7: xk=-4.547663995884454e29\n",
      "Its=8: xk=-5.621746013750659e59\n",
      "Its=9: xk=-8.59086556793834e119\n",
      "Its=10: xk=-2.0061727551661208e240\n",
      "Its=11: xk=-Inf\n",
      "With starting points x0=1.0: the reciprocal of e = 2.7182818284590... is -Inf; and iterations=11.\n"
     ]
    }
   ],
   "source": [
    "d=e\n",
    "println(\"The reciprocal of \",d,\" is: \", 1/d,\".\")\n",
    "x0=0.3;\n",
    "x,its=reciprocal_newton(d,x0)\n",
    "println(\"With starting points x0=\",x0,\": the reciprocal of \",d,\" is \",x,\"; and iterations=\", its,\".\")\n",
    "x0=1.0; d=e;\n",
    "x,its=reciprocal_newton(d,x0)\n",
    "println(\"With starting points x0=\",x0,\": the reciprocal of \",d,\" is \",x,\"; and iterations=\", its,\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, for the pure Newton's method, it is very important to choose a \"good\" starting point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##(a)\n",
    "\n",
    "For $f(x)=x^q=0$ with $q>2$, Newton's method is \n",
    "$$x_{k+1}= x_k-\\frac{f(x_k}{f'(x_k)}\\qquad \\text{for }k=0,1,\\cdots$$\n",
    "where $$ f(x_k)=x_k^q\\quad\\text{ and }\\quad f'(x_k)=qx_k^{q-1}.$$\n",
    "So \n",
    "$$x_{k+1}= (1-\\frac{1}{q})x_k\\qquad \\text{for }k=0,1,\\cdots$$\n",
    "Then\n",
    "$$\\frac{\\|x_{k+1}-x^*\\|}{\\|x_{k}-x^*\\|}=\\frac{\\|(1-\\frac{1}{q})x_k-0\\|}{\\|x_{k}-0\\|}=1-\\frac{1}{q}<1\\qquad\\text{for }k\\geq 0$$\n",
    "\n",
    "From above, we can see that Newton's method applibed to $f(x)=0$ converges Q-linearly, and \n",
    "the convergence ratio is $1-\\frac{1}{q}$.\n",
    "\n",
    "##(b)\n",
    "For $x=(x_1,\\cdots,x_n)$, for $x\\neq 0$,\n",
    "$$f(x)=\\|x\\|_2^{\\beta}=\\left(\\sum_{i=1}^nx_i^2\\right)^{\\frac{\\beta}{2}}$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x_i}=\\frac{\\beta}{2}\\left(\\sum_{i=1}^nx_i^2\\right)^{\\frac{\\beta}{2}-1}\\dot(2x_i)=\\beta\\left(\\sum_{i=1}^nx_i^2\\right)^{\\frac{\\beta}{2}-1}x_i=\\beta\\|x\\|_2^{\\beta-2}x_i$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\frac{\\partial^2f}{\\partial x_i\\partial x_j}=\\beta\\left(\\frac{\\beta}{2}-1\\right)\\left(\\sum_{i=1}^nx_i^2\\right)^{\\frac{\\beta}{2}-2}x_i(2x_j)=\\beta(\\beta-2)\\|x\\|_2^{\\beta-2}x_ix_j\\quad\\text{ for }i\\neq j$$\n",
    "\n",
    "$$\\frac{\\partial^2f}{\\partial x_i^2}=\\beta\\|x\\|_2^{\\beta-2}+\\beta(\\beta-2)\\|x\\|_2^{\\beta-4}x_i^2.$$\n",
    "\n",
    "So \n",
    "$$\\nabla f=\\beta\\|x\\|_2^{\\beta-2}x \\qquad \\text{ and }\\qquad \\nabla^2f=\\beta\\|x\\|_2^{\\beta-2}I+\\beta(\\beta-2)\\|x\\|_2^{\\beta-4}xx'.$$\n",
    "\n",
    "\n",
    "Then \n",
    "\\begin{align*}\n",
    "(\\nabla^2f)^{-1}\n",
    "&=\\left(\\beta\\|x\\|_2^{\\beta-2}\\left(I+\\frac{\\beta-2}{\\|x\\|_2^2}xx'\\right)\\right)^{-1}=\\frac{1}{\\beta\\|x\\|_2^{\\beta-2}}\\left( I-\\frac{\\frac{\\beta-2}{\\|x\\|_2^2}}{1+\\frac{\\beta-2}{\\|x\\|_2^2}\\|x\\|_2^2}xx'\\right) \\\\\n",
    "\\\\\n",
    "&=\\beta^{-1}\\|x\\|_2^{2-\\beta}\\left(I-\\frac{\\beta-2}{\\beta-1}\\frac{xx'}{\\|x\\|_2^2} \\right)\n",
    "\\end{align*}\n",
    "\n",
    "So the pure form of Newton's method to minimization of the function $f(x)=\\|x\\|_2^{\\beta}$ is given as below:\n",
    "\n",
    "\\begin{align*}\n",
    "x^{k+1}\n",
    "& =x^k-(\\nabla^2f(x^k))^{-1}\\nabla f(x^k) \\\\\n",
    "\\\\\n",
    "& =x^k-\\frac{1}{\\beta}\\|x^k\\|_2^{2-\\beta}\\left(I-\\frac{\\beta-2}{\\beta-1}\\frac{x^k(x^k)'}{\\|x^k\\|_2^2} \\right)\\beta\\|x^k\\|_2^{\\beta-2}x^k\\\\\n",
    "\\\\\n",
    "&=\\frac{\\beta-2}{\\beta-1}x^k.\n",
    "\\end{align*}\n",
    "\n",
    "Then we have \n",
    "$$x^k=\\left(\\frac{\\beta-2}{\\beta-1}\\right)^kx^0.$$\n",
    "\n",
    "It is easy to see that the minimizer in this problem is $0$. Then for $\\left|\\frac{\\beta-2}{\\beta-1}\\right|<1\\Leftrightarrow\\beta>3/2$,  with any starting point $x^0$, $x^k\\rightarrow 0$ as $n\\rightarrow\\infty$, i.e. for $\\beta>3/2$ and any starting point $x^0$, $x^k$ converges to the minimizer. Moreover, $x_k$ converges in one step when $\\beta=2$ and when $\\beta\\neq 2$ and $\\beta>3/2$,\n",
    "\n",
    "$$\\frac{\\|x^{k+1}-x^*\\|}{\\|x^{k}-x^*\\|}=\\left|\\frac{\\beta-2}{\\beta-1}\\right|, $$\n",
    "\n",
    "which means the $x_k$ converges to $0$ Q-linearly and the convergence ratio is $\\left|\\frac{\\beta-2}{\\beta-1}\\right|$.\n",
    "\n",
    "For $\\beta=1$, we have\n",
    "$$\\nabla f=\\frac{x}{\\|x\\|_2}\\qquad \\text{ and }\\qquad \\nabla^2f=\\frac{1}{\\|x\\|_2}\\left(I-\\frac{xx'}{\\|x\\|_2^2}\\right).$$\n",
    "\n",
    "Denote $P=I-\\frac{xx'}{\\|x\\|_2^2}$, it is easy to see that $P^2=P$ and $P^T=P$. Then\n",
    "\n",
    "$${\\rm rank}(P)={\\rm tr}(P)={\\rm tr}(I)-{\\rm tr}\\left(\\frac{xx'}{\\|x\\|_2^2}\\right)=n-1.$$\n",
    "\n",
    "So $\\nabla^2f(x)$ is not full-rank, which means that the pure Newton's method cannot work.\n",
    "\n",
    "For $\\beta<1$, in the same way, \n",
    "$$x^k=\\left(\\frac{\\beta-2}{\\beta-1}\\right)^kx^0.$$\n",
    "\n",
    "When $x^0\\neq 0$, $x^k\\rightarrow \\infty$ as $n\\rightarrow \\infty$.\n",
    "\n",
    "Moreover, the eigenvalues of \n",
    "\n",
    "$$\\nabla^2f=\\beta\\|x\\|_2^{\\beta-2}\\left(I+\\frac{\\beta-2}{\\|x\\|_2^2}xx'\\right)$$\n",
    "\n",
    "is $(n-1)$ one's and $\\beta(\\beta-1)\\|x\\|_2^{\\beta-2}$, which means that the Hessian is positive definite if and only if $\\beta>1$.\n",
    "\n",
    "In conclusion, when $x^0\\neq 0$: \n",
    "\n",
    "* if $\\beta>3/2$ but $\\beta\\neq 2$, $x^k$ converges to $0$ Q-linearly and the convergence ratio is $\\left|\\frac{\\beta-2}{\\beta-1}\\right|$;\n",
    "\n",
    "* if $\\beta=2$, $x_k$ converges in one step;\n",
    "\n",
    "* if $\\beta=3/2$, $x_k=x_0\\text{ or }-x_0$;\n",
    "\n",
    "* if $\\beta=1$, the pure Newton's method cannot work since $(\\nabla^2f)^{-1}$ does not exists;\n",
    "\n",
    "* if $\\beta<3/2$ but $\\beta\\neq 1$, $x_k\\rightarrow\\infty$ as $n\\rightarrow\\infty$.\n",
    "\n",
    "When $x^0=0$, the pure Newton's method converges automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##(c)\n",
    "For Newton's method with an Armijo linesearch,\n",
    "\n",
    "\\begin{align*}\n",
    "x^{k+1}\n",
    "& =x^k-\\alpha_k(\\nabla^2f(x^k))^{-1}\\nabla f(x^k) \\\\\n",
    "\\\\\n",
    "& =x^k-\\frac{\\alpha_k}{\\beta}\\|x^k\\|_2^{2-\\beta}\\left(I-\\frac{\\beta-2}{\\beta-1}\\frac{x^k(x^k)'}{\\|x^k\\|_2^2} \\right)\\beta\\|x^k\\|_2^{\\beta-2}x^k\\\\\n",
    "\\\\\n",
    "&=\\left(1-\\frac{\\alpha_k}{\\beta-1}\\right)x^k.\n",
    "\\end{align*}\n",
    "\n",
    "So  \n",
    "$$x^k=\\prod_{i=0}^{k-1}\\left(1-\\frac{\\alpha_i}{\\beta-1}\\right)x^0.$$\n",
    "For the Armijo condition, we need to find $\\alpha_k$ satistifying\n",
    "\n",
    "$$f(x^k+\\alpha_k d_k)\\leq f(x^k)+c_1\\alpha_k\\nabla f(x^k)^Td_k.$$\n",
    "\n",
    "For $\\beta\\neq 1$, \n",
    "$$d_k=-\\nabla^2f(x^k))^{-1}\\nabla f(x^k)=-\\frac{1}{\\beta-1}x^k\\quad\\text{and}\\quad \\nabla f(x^k)=\\beta\\|x^k\\|_2^{\\beta-2}x^k.$$\n",
    "\n",
    "Then we have $\\alpha_k$ satisfy the following inequalify:\n",
    "\n",
    "$$\\left\\Vert\\left(1-\\frac{\\alpha_k}{\\beta-1}\\right)x^k\\right\\Vert^{\\beta}\\leq \\|x^k\\|^{\\beta}-c_1\\alpha_k\\frac{\\beta}{\\beta-1}\\|x^k\\|^{\\beta}.$$\n",
    "\n",
    "i.e.\n",
    "\n",
    "$$\\left|1-\\frac{\\alpha_k}{\\beta-1}\\right|^\\beta\\|x^k\\|^\\beta\\leq \\left(1-c_1\\alpha_k\\frac{\\beta}{\\beta-1}\\right)\\|x^k\\|^\\beta.$$\n",
    "\n",
    "From the inequalify above, for $\\beta\\neq 1$, before $x^k$ reaching $0$, the Arimijo linesearch gives us the same $\\alpha_k=\\alpha$ such that \n",
    "$$\\left|1-\\frac{\\alpha}{\\beta-1}\\right|\\leq \\left(1-c_1\\alpha\\frac{\\beta}{\\beta-1}\\right)^{\\frac{1}{\\beta}}$$.\n",
    "\n",
    "Thus, for $x^0\\neq 0$, \n",
    "$$x^k=\\left(1-\\frac{\\alpha}{\\beta-1}\\right)^kx^0.$$\n",
    "\n",
    "So when $\\beta>1$, we have $c_1\\alpha\\frac{\\beta}{\\beta-1}>0$, then\n",
    "$$0\\leq\\left|1-\\frac{\\alpha}{\\beta-1}\\right|\\leq \\left(1-c_1\\alpha\\frac{\\beta}{\\beta-1}\\right)^{\\frac{1}{\\beta}}<1.$$\n",
    "\n",
    "Then $x^k$ converges to 0 Q-linearly and the convergence ratio is $|1-\\frac{\\alpha}{\\beta-1}|$.\n",
    "\n",
    "When $\\beta<1$, we have $$|1-\\frac{\\alpha}{\\beta-1}|=1+\\frac{\\alpha}{1-\\beta}>1,$$\n",
    "so $x^k\\rightarrow\\infty$ as $k\\rightarrow\\infty$ when $x^0\\neq 0$.\n",
    "\n",
    "When $\\beta=1$, in the same way as in part (b), the Newton's method can not work since the inverse of the Hessian matrix does not exist.\n",
    "\n",
    "In conclusion, when $x^0\\neq0$,\n",
    "* if $\\beta>1$, $x^k$ converges to 0 Q-linearly and the convergence ratio is $|1-\\frac{\\alpha}{\\beta-1}|$;\n",
    "\n",
    "* if $\\beta=1$, the Newton's method cannot work;\n",
    "\n",
    "* if $\\beta<1$, $x^k\\rightarrow\\infty$ as $k\\rightarrow\\infty$;\n",
    "\n",
    "When $x^0=0$, the Newton's method converges automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary: from the results in part (b) and part (c), pure Newton's problem works only when $\\beta>3/2$; however, Newton's method with an Armijo linesearch works for all the $\\beta>1$ (the strong convex case) and fails only when the problem is not strong convex ($\\beta\\geq 1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exercise 3\n",
    "###(1) Show $D^{k+1}q^i=p^i$ for all $k\\geq 0$ and $i\\leq k$.\n",
    "\n",
    "###(a) $k=0$: \n",
    "We have \n",
    "$$D^1=D^0+\\frac{y^0(y^0)'}{(q^0)'y^0}\\qquad\\text{and}\\qquad y^0=p^0-D^0q^0.$$\n",
    "So\n",
    "$$D^1q^0=\\left(D^0+\\frac{y^0(y^0)'}{(q^0)'y^0}\\right)q^0=D^0q^0+\\frac{y^0(y^0)'}{(q^0)'y^0}q^0=D^0q^0+y^0=p^0.$$\n",
    "\n",
    "###(b) Assume $D^kq^i=p^i$ for all $i\\leq k-1$\n",
    "By calculation,\n",
    "$$D^{k+1}q^k=\\left(D^k+\\frac{y^k(y^k)'}{(q^k)'y^k}\\right)q^k=D^kq^k+\\frac{y^k(y^k)'}{(q^k)'y^k}q^k=D^kq^k+y^k=p^k.$$\n",
    "\n",
    "For $i\\leq k-1$,\n",
    "\\begin{align*}\n",
    "D^{k+1}q^i=\\left(D^k+\\frac{y^k(y^k)'}{(q^k)'y^k}\\right)q^i & =D^kq^i+\\frac{y^k(y^k)'}{(q^k)'y^k}q^i\\\\\n",
    "\\\\\n",
    "&=p^i+\\frac{y^k}{(q^k)'y^k}(p^k-D^kq^k)'q^i\\qquad\\text{since } D^kq^i=p^i \\text{for all }i\\leq k-1 \\text{ and }D^kq^k+y^k=p^k\\\\\n",
    "\\\\\n",
    "&=p^i+\\frac{y^k}{(q^k)'y^k}\\left((p^k)'q^i-(q^k)'D^kq^i\\right) \\qquad\\text{since by definition, }D^{k}\\text{ is symmetric}\\\\\n",
    "\\\\\n",
    "&=p^i+\\frac{y^k}{(q^k)'y^k}\\left((p^k)'q^i-(q^k)'p^i\\right)\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "For the positive-definite quadratic function $f(x)=\\frac{1}{2}x'Qx-bx$, \n",
    "$$\\nabla f(x)=Qx.$$\n",
    "\n",
    "By definition \n",
    "$$p^k=x^{k+1}-x^k\\quad\\text{and}\\quad q^k=\\nabla f(x^{k+1})-\\nabla f(x^k)=Qx^{k+1}-Qx^k=Q(x^{k+1}-x^k)=Qp^k.$$\n",
    "\n",
    "Then\n",
    "$$(p^k)'q^i-(q^k)'p^i=(p^k)'Qp^i-(Qp^k)'p^i=(p^k)'Qp^i-(p^k)'Qp^i=0.$$\n",
    "\n",
    "So we have $D^{k+1}q^i=p^i$ for all $i\\leq k$.\n",
    "\n",
    "By (a) and (b), $D^{k+1}q^i=p^i$ for all $k\\geq 0$ and $i\\leq k$.\n",
    "\n",
    "###(2) Show $D^n$ is equal to the inverse Hessian of the cost function.\n",
    "\n",
    "Since $D^{n}q^i=p^i$ for all $i\\leq n-1$, we have\n",
    "$$D^n[q^0,q^1,\\cdots,q^{n-1}]=[p^0,p^1,\\cdots,p^{n-1}]$$\n",
    "\n",
    "Also, $q^0, q^1, \\cdots, q^{n-1}$ are linerly independent, then\n",
    "$$D^n=[p^0,p^1,\\cdots,p^{n-1}][q^0,q^1,\\cdots,q^{n-1}]^{-1}$$\n",
    "\n",
    "From (1), we know that $q^k=Qp^k$, then we have\n",
    "\\begin{align}\n",
    "D^n\n",
    "&=[p^0,p^1,\\cdots,p^{n-1}][Qp^0,Qp^1,\\cdots,Qp^{n-1}]^{-1}\\\\\n",
    "\\\\\n",
    "&=[p^0,p^1,\\cdots,p^{n-1}](Q[p^0,p^1,\\cdots,p^{n-1}])^{-1}\\\\\n",
    "\\\\\n",
    "&=[p^0,p^1,\\cdots,p^{n-1}][p^0,p^1,\\cdots,p^{n-1}]^{-1}Q^{-1}\\\\\n",
    "\\\\\n",
    "&=Q^{-1}\n",
    "\\end{align}\n",
    "i.e.$D^n$ is equal to the inverse Hessian of the cost function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table that shows the performaceof BFGS with backtracking linesearch vs Newton for each problem in the Toms566 collections is already in homework 3. From the results, we can see that in order to get good results of the BFGS method, we need to choose different $r$. Moreover, from the definition of the Wolfe condition, it is easy to see that only backtracking is not enough. Here I tried a bisection method for the wolfe condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding a BFGS quasi-Newton option to your Newton code from last week, my function is as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p2obj (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function newtmin(obj,x0,method;eps=1e-8,maxIts=1000,optTol=1e-8,r=0.9,c1=1e-4,c2=0.9)\n",
    "    # Minimize a function f using Netown's method.\n",
    "    #obj: a function that evaluates the objective values, gradient and Hessian at a point x, i.e., (f,g,H)=obj(x)\n",
    "    #x0: starting point\n",
    "    #maxIts: maximum number of iterations\n",
    "    #optTol: optimality toleracne based on ||grad(x)||<=optTol*||grad(x0)||\n",
    "    if method==\"newton\"\n",
    "        g=obj(x0)[2]\n",
    "        H=obj(x0)[3]\n",
    "        its=0;g0=g;x=x0\n",
    "        G=Float64[]\n",
    "        while norm(g)>optTol && its<maxIts\n",
    "            push!(G,norm(g))\n",
    "            D,V=eig(H)\n",
    "            H=V*Diagonal(map(x->1/max(abs(x),eps),D))*V'\n",
    "            d=-H*g\n",
    "            x=x+btls(obj,x,d,g,r,c1)*d\n",
    "            its=its+1\n",
    "            g=obj(x)[2]\n",
    "            H=obj(x)[3]\n",
    "        end\n",
    "    elseif method==\"bfgs\"\n",
    "        f0,g0,H0=obj(x0)\n",
    "        D,V=eig(H0)\n",
    "        H0=V*Diagonal(map(x->1/max(x,1),D))*V'\n",
    "        its=0;ng=norm(g0)\n",
    "        G=Float64[]\n",
    "        while norm(g0)>optTol && its<maxIts\n",
    "            push!(G,norm(g0))\n",
    "            d=-H0*g0\n",
    "            x=x0+bisection_wolfe(obj,x0,d,c1,c2,r)*d\n",
    "            g=obj(x)[2]\n",
    "            s=x-x0; y=g-g0\n",
    "            rho=1/dot(y,s)\n",
    "            H=(eye(H0)-rho*s*y')*H0*(eye(H0)-rho*y*s')+rho*s*s'\n",
    "            its=its+1\n",
    "            x0=x;g0=g;H0=H\n",
    "        end\n",
    "    else \n",
    "        println(\"Please enter netwon or bfgs!\")\n",
    "    end\n",
    "    return x,its,G\n",
    "end\n",
    "\n",
    "function btls(obj,x,d,g,r,c1;a=1,maxIts=100)\n",
    "    for i=1:maxIts\n",
    "        a=a*r\n",
    "        if obj(x+a*d)[1]<=obj(x)[1]+a*c1*dot(g,d)\n",
    "            break\n",
    "        end\n",
    "     end\n",
    "    return a\n",
    "end\n",
    "\n",
    "function bisection_wolfe(obj,x0,d,c1,c2,r; maxIts=25)\n",
    "    a=0;t=1;b=Inf\n",
    "    f0,g0=obj(x0)\n",
    "    for i=1:maxIts\n",
    "        f,g,H=obj(x0+t*d)\n",
    "        if f>f0+c1*dot(g0,d)\n",
    "            b=t; t=a*(1-r)+b*r\n",
    "        elseif dot(g,d)<c2*dot(g0,d)\n",
    "            a=t;\n",
    "            if b==Inf\n",
    "                t=2*a\n",
    "            else\n",
    "                t=a*(1-r)+b*r\n",
    "            end\n",
    "        else\n",
    "           break;\n",
    "        end\n",
    "    end\n",
    "        return t\n",
    "end\n",
    "\n",
    "function p2obj(p)\n",
    "    function obj(x)\n",
    "        return (p.obj(x),p.grd(x),p.hes(x))\n",
    "    end\n",
    "    return obj\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the BFGS method, I can get the results as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the BFGS method: \n",
      "No.  Name                             n   Its         f(x)      |∇f(x)| cond(∇²f(x))\n",
      "  1  Hellical valley                  3    31     9.27e-24     6.92e-11     4.94e+02\n",
      "  2  Bigg's EXP6                      6   108     2.95e-22     2.82e-11     3.98e+01\n",
      "  3  Gaussian                         3     4     1.13e-08     6.98e-11     5.13e+01\n",
      "  4  Powell                           2   172     1.24e-32     2.02e-11     6.88e+17\n",
      "  5  Box 3-dim                        3    20     2.87e-23     1.87e-11     5.04e+17\n",
      "  6  Variably dimensioned            40   693     2.15e-27     2.64e-12     9.04e+03\n",
      "  7  Watson                           9   101     1.40e-06     7.20e-11     3.80e+01\n",
      "  8  Penalty I                       60   450     5.25e-04     8.91e-11     6.47e+03\n",
      "  9  Penalty II                      65   250     8.80e+01     9.42e-11     1.00e+04\n",
      " 10  Brown badly scaled               2    47     0.00e+00     0.00e+00     1.00e+12\n",
      " 11  Brown and Denis                  4    46     8.58e+04     3.34e-11     8.46e+01\n",
      " 12  Gulf research and development    3    34     2.83e-22     8.54e-12     6.96e+06\n",
      " 13  Trigonometric                   40   254     3.95e-06     9.55e-11     3.28e+01\n",
      " 14  Extended rosenbrock             40   280     3.61e-21     8.26e-11     3.90e+03\n",
      " 15  Extended Powell singular        60   650     1.49e-16     4.78e-11     1.47e+10\n",
      " 16  Beale                            2    17     6.71e-23     3.58e-11     1.62e+02\n",
      " 17  Wood                             4    84     4.43e-25     2.20e-11     1.40e+03\n",
      " 18  Chebyquad                       50   408     5.39e-03     7.84e-11     6.95e+02\n"
     ]
    }
   ],
   "source": [
    "using Toms566\n",
    "println(\"For the BFGS method: \")\n",
    "@printf(\"%3s  %-30s %3s %5s %12s %12s %12s\\n\",\"No.\",\"Name\",\"n\",\"Its\",\n",
    "        \"f(x)\",\"|∇f(x)|\",\"cond(∇²f(x))\")\n",
    "for i=1:18\n",
    "p = Problem(i)\n",
    "x,its,G=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=2000, optTol=1e-10, r=0.6)\n",
    "@printf(\"%3i  %-30s %3i %5i %12.2e %12.2e %12.2e\\n\",\n",
    " i, p.name, p.n, its, p.obj(x), norm(p.grd(x)), cond(p.hes(x)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, we can see that the BFGS method with a bisection method for the wolfe conditions works pretty good for all of the Toms' problem. If we choose $r=0.6$, then all the Toms' problems converges in the sense $|∇f(x)|<1e-10$. \n",
    "\n",
    "Moreover, we can get the table comparing the performace of Newton vs BFGS for each problem in the Toms566 collections as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.   n  Newton: Its        f(x)      |∇f(x)| cond(∇²f(x))    BFGS: Its        f(x)      |∇f(x)| cond(∇²f(x))\n",
      "  1   3          164     3.55e-19     6.86e-09     4.94e+02           30     1.03e-19     9.12e-09     4.94e+02\n",
      "  2   6         1000     5.94e-04     1.71e-03     1.43e+02          106     5.31e-18     9.64e-10     3.98e+01\n",
      "  3   3            6     1.13e-08     7.45e-09     5.13e+01            4     1.13e-08     6.98e-11     5.13e+01\n",
      "  4   2           94     5.41e-27     7.42e-09     6.88e+17          172     1.24e-32     2.02e-11     6.88e+17\n",
      "  5   3           28     4.16e-17     5.84e-09     8.34e+03           20     2.87e-23     1.87e-11     5.04e+17\n",
      "  6  40         1000     1.73e+01     1.95e+01     9.12e+03          692     3.90e-24     5.12e-10     9.04e+03\n",
      "  7   9         1000     4.32e-04     2.81e-02     3.73e+01          100     1.40e-06     3.39e-09     3.80e+01\n",
      "  8  60           26     5.25e-04     3.81e-09     6.46e+03          368     5.25e-04     3.95e-09     6.89e+03\n",
      "  9  65         1000     8.80e+01     6.75e-03     3.73e+05          218     8.80e+01     9.12e-09     1.00e+04\n",
      " 10   2           23     7.89e-31     1.78e-09     1.00e+12           47     0.00e+00     0.00e+00     1.00e+12\n",
      " 11   4           46     8.58e+04     5.07e-09     8.46e+01           36     8.58e+04     1.01e-09     8.46e+01\n",
      " 12   3           30     4.62e-19     4.73e-09     6.96e+06           33     2.49e-18     8.34e-09     6.96e+06\n",
      " 13  40          208     4.83e-17     9.72e-09     2.45e+01           57     3.95e-06     8.27e-09     3.28e+01\n",
      " 14  40         1000     6.50e+01     1.32e+01     3.41e+03          267     1.87e-18     4.24e-09     3.90e+03\n",
      " 15  60         1000     3.84e-03     1.10e-01     1.90e+03          462     1.50e-12     6.20e-09     9.24e+07\n",
      " 16   2           13     3.06e-20     1.34e-09     1.62e+02           16     1.07e-18     9.67e-09     1.62e+02\n",
      " 17   4           45     4.84e-20     5.39e-09     1.40e+03           83     2.65e-21     9.61e-10     1.40e+03\n",
      " 18  50         1000     6.67e-03     3.56e-02     3.57e+02          397     5.39e-03     9.10e-09     6.95e+02\n"
     ]
    }
   ],
   "source": [
    "using Toms566\n",
    "@printf(\"%3s %3s %12s %11s %12s %12s %12s %11s %12s %12s\\n\",\n",
    "\"No.\",\"n\",\"Newton: Its\",\"f(x)\",\"|∇f(x)|\",\"cond(∇²f(x))\",\"BFGS: Its\",\"f(x)\",\"|∇f(x)|\",\"cond(∇²f(x))\")\n",
    "for i=1:18\n",
    "   p=Problem(i)\n",
    "   x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=1000,optTol=1e-8)\n",
    "   x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "   @printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "            i,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more precise result is listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.   n  Newton: Its        f(x)      |∇f(x)| cond(∇²f(x))    BFGS: Its        f(x)      |∇f(x)| cond(∇²f(x))\n",
      "  1   3          164     3.55e-19     6.86e-09     4.94e+02           30     1.03e-19     9.12e-09     4.94e+02\n",
      "  2   6       837459     2.32e-12     1.00e-08     3.98e+01          106     5.31e-18     9.64e-10     3.98e+01\n",
      "  3   3            6     1.13e-08     7.45e-09     5.13e+01            4     1.13e-08     6.98e-11     5.13e+01\n",
      "  4   2           94     5.41e-27     7.42e-09     6.88e+17          172     1.24e-32     2.02e-11     6.88e+17\n",
      "  5   3           28     4.16e-17     5.84e-09     8.34e+03           20     2.87e-23     1.87e-11     5.04e+17\n",
      "  6  40       100389     2.42e-17     1.00e-08     9.04e+03          692     3.90e-24     5.12e-10     9.04e+03\n",
      "  7   9         1000     4.32e-04     2.81e-02     3.73e+01          100     1.40e-06     3.39e-09     3.80e+01\n",
      "  8  60           26     5.25e-04     3.81e-09     6.46e+03          368     5.25e-04     3.95e-09     6.89e+03\n",
      "  9  65        25375     8.80e+01     9.95e-09     1.00e+04          218     8.80e+01     9.12e-09     1.00e+04\n",
      " 10   2           23     7.89e-31     1.78e-09     1.00e+12           47     0.00e+00     0.00e+00     1.00e+12\n",
      " 11   4           46     8.58e+04     5.07e-09     8.46e+01           36     8.58e+04     1.01e-09     8.46e+01\n",
      " 12   3           30     4.62e-19     4.73e-09     6.96e+06           33     2.49e-18     8.34e-09     6.96e+06\n",
      " 13  40          208     4.83e-17     9.72e-09     2.45e+01           57     3.95e-06     8.27e-09     3.28e+01\n",
      " 14  40        10000     6.05e-01     1.67e+00     2.83e+03          267     1.87e-18     4.24e-09     3.90e+03\n",
      " 15  60        10000     4.98e-04     1.62e-02     2.06e+04          462     1.50e-12     6.20e-09     9.24e+07\n",
      " 16   2           13     3.06e-20     1.34e-09     1.62e+02           16     1.07e-18     9.67e-09     1.62e+02\n",
      " 17   4           45     4.84e-20     5.39e-09     1.40e+03           83     2.65e-21     9.61e-10     1.40e+03\n",
      " 18  50         5000     6.46e-03     6.94e-03     3.97e+02          397     5.39e-03     9.10e-09     6.95e+02\n"
     ]
    }
   ],
   "source": [
    "using Toms566\n",
    "@printf(\"%3s %3s %12s %11s %12s %12s %12s %11s %12s %12s\\n\",\n",
    "\"No.\",\"n\",\"Newton: Its\",\"f(x)\",\"|∇f(x)|\",\"cond(∇²f(x))\",\"BFGS: Its\",\"f(x)\",\"|∇f(x)|\",\"cond(∇²f(x))\")\n",
    "p=Problem(1)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=1000,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    1,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(2)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=1e6,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    2,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(3)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=1000,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    3,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(4)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=1000,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    4,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(5)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=1000,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    5,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(6)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=2e5,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    6,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(7)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=1000,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    7,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(8)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=1000,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    8,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(9)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=1e5,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    9,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(10)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=1000,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    10,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(11)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=1000,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    11,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(12)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=1000,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    12,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(13)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=1000,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    13,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(14)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=10000,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    14,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(15)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=10000,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    15,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(16)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=1000,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    16,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(17)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=1000,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    17,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))\n",
    "p=Problem(18)\n",
    "x1,its1=newtmin(p2obj(p),p.x0,\"newton\",maxIts=5000,optTol=1e-8)\n",
    "x2,its2=newtmin(p2obj(p),p.x0,\"bfgs\",maxIts=1000,r=0.6,optTol=1e-8)\n",
    "@printf(\"%3i %3i %12i %12.2e %12.2e %12.2e %12i %12.2e %12.2e %12.2e\\n\",\n",
    "    18,p.n,its1,p.obj(x1),norm(p.grd(x1)),cond(p.hes(x1)),its2,p.obj(x2),norm(p.grd(x2)),cond(p.hes(x2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table, the Modified Newton's method can work for most of the problems, but some of them converges in a very slow pace. However, the BFGS quasi-Newton's methods converges in less than 1000 steps for all of the problems. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.0",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
